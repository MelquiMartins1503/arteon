import { GoogleGenerativeAI } from "@google/generative-ai";
import { type NextRequest, NextResponse } from "next/server";
import { CHAT_CONFIG } from "@/config/chat.config";
import {
  buildInitialChatSystemPrompt,
  buildPauseModeOverrideMessage,
  IDEALIZATION_END_MESSAGE_MODEL,
  IDEALIZATION_END_MESSAGE_USER,
} from "@/features/story/prompts/chat";
import { apiErrorHandler } from "@/lib/apiErrorHandlers";
import { env } from "@/lib/env";
import { HttpExceptionClient } from "@/lib/exceptions/HttpExceptions";
import { getAuthenticatedUser } from "@/lib/getAuthenticatedUser";
import logger from "@/lib/logger";
import prismaClient from "@/lib/prismaClient";
import { chatRequestSchema } from "@/lib/schemas/chatRequest";
import {
  CommandDetector,
  HistoryOptimizer,
  MessageSummarizer,
  SelectiveHistoryLoader,
  SuggestionGenerator,
} from "@/services/chat";
import { handlePauseModeCommands } from "@/services/chat/PauseModeHandler";
import { GeminiClient } from "@/services/gemini/GeminiClient";
import {
  EntityManager,
  type ExtractionResult,
  KnowledgeBaseFormatter,
  KnowledgeExtractor,
  RelationshipManager,
} from "@/services/knowledge";
import type { GeminiMessage } from "@/types/chat";

export async function POST(
  request: NextRequest,
  { params }: { params: Promise<{ uuid: string }> },
) {
  try {
    const user = await getAuthenticatedUser();
    const { uuid } = await params;

    // Validar body com schema atualizado
    const body = await request.json();
    const { prompt, important, isMeta, generateSuggestions, imageUrls } =
      chatRequestSchema.parse(body);

    // Buscar hist√≥ria
    const story = await prismaClient.story.findUnique({
      where: { uuid: uuid },
      include: {
        conversationHistory: true,
      },
    });

    if (!story) {
      throw new HttpExceptionClient(404, "Hist√≥ria n√£o encontrada");
    }

    if (story.userId !== user.id) {
      throw new HttpExceptionClient(404, "Hist√≥ria n√£o encontrada");
    }

    // Tratamento para inconsist√™ncias onde o Prisma pode retornar array ou objeto
    const historyData = story.conversationHistory;
    const chatSessionReference = Array.isArray(historyData)
      ? historyData[0]
      : historyData;

    if (!chatSessionReference) {
      throw new HttpExceptionClient(
        404,
        "Hist√≥rico de conversas n√£o encontrado",
      );
    }

    // Buscar mensagens explicitamente (excluindo consultas com isMeta: true)
    const conversationHistoryWithMessages =
      await prismaClient.conversationHistory.findUnique({
        where: { id: chatSessionReference.id },
        select: {
          id: true,
          customPrompt: true,
          pauseNarrativeMode: true, // CARREGAR ESTADO DO MODO PAUSA
          messages: {
            where: { isMeta: false },
            orderBy: { id: "asc" },
          },
        },
      });

    if (!conversationHistoryWithMessages) {
      throw new HttpExceptionClient(
        404,
        "Hist√≥rico de conversas n√£o encontrado ao buscar mensagens",
      );
    }

    // ========================================================================
    // DETEC√á√ÉO DE COMANDOS E INFER√äNCIA DE TIPOS
    // ========================================================================
    // ========================================================================
    const commandDetector = new CommandDetector();
    const rawCommand = commandDetector.detectNarrativeCommand(prompt);
    const isInPauseMode = conversationHistoryWithMessages.pauseNarrativeMode;

    // ========================================================================
    // SEPARAR: Comando para HIST√ìRICO vs Comando para TIPOS DE MENSAGEM
    // ========================================================================
    // O comando para carregamento de hist√≥rico pode ser sobrescrito pelo modo pausa,
    // MAS o comando para classifica√ß√£o de mensagens deve SEMPRE ser o real
    let historyLoadingCommand = rawCommand;
    const messageClassificationCommand = rawCommand;

    if (isInPauseMode && rawCommand !== "RETOMAR_NARRATIVA") {
      // Durante modo pausa, SEMPRE usar config de pausa para HIST√ìRICO
      historyLoadingCommand = "PAUSAR_NARRATIVA";
      logger.info(
        { rawCommand, isInPauseMode },
        "Em modo PAUSAR NARRATIVA - for√ßando configura√ß√£o de pausa para hist√≥rico",
      );
    } else if (!isInPauseMode && rawCommand === "GENERAL") {
      // Fora do modo pausa, mensagens sem comando tamb√©m usam pausa para HIST√ìRICO
      historyLoadingCommand = "PAUSAR_NARRATIVA";
      logger.info(
        "Mensagem sem comando - usando configura√ß√£o de pausa para hist√≥rico",
      );
    }

    // Converter para tipo seguro (nunca GENERAL) - apenas para hist√≥rico
    const detectedCommand: Exclude<typeof historyLoadingCommand, "GENERAL"> =
      historyLoadingCommand === "GENERAL"
        ? "PAUSAR_NARRATIVA"
        : historyLoadingCommand;

    // ‚úÖ USAR COMANDO REAL para inferir tipos de mensagem
    const userMessageType = commandDetector.inferUserMessageType(
      messageClassificationCommand,
    );
    const responseMessageType = commandDetector.inferResponseMessageType(
      messageClassificationCommand,
    );

    logger.info(
      {
        rawCommand,
        historyLoadingCommand: detectedCommand,
        messageClassificationCommand,
        userMessageType,
        responseMessageType,
      },
      "Comando narrativo detectado",
    );

    // ========================================================================
    // INTERCEPTA√á√ÉO: ATIVAR/DESATIVAR MODO PAUSA
    // ========================================================================
    const pauseModeResponse = await handlePauseModeCommands(
      rawCommand,
      prompt,
      isInPauseMode,
      conversationHistoryWithMessages.id,
      prismaClient,
    );

    if (pauseModeResponse) {
      return pauseModeResponse;
    }

    // ========================================================================
    // INTERCEPTA√á√ÉO DE COMANDO: FINALIZAR IDEALIZA√á√ÉO
    // ========================================================================

    if (commandDetector.isFinalizeIdealizationCommand(prompt)) {
      // Salvar mensagem do usu√°rio
      await prismaClient.message.create({
        data: {
          content: IDEALIZATION_END_MESSAGE_USER,
          role: "USER",
          conversationHistoryId: conversationHistoryWithMessages.id,
          important: false,
          isMeta: true,
          messageType: "SYSTEM",
        },
      });

      // Salvar resposta do modelo
      await prismaClient.message.create({
        data: {
          content: IDEALIZATION_END_MESSAGE_MODEL,
          role: "MODEL",
          conversationHistoryId: conversationHistoryWithMessages.id,
          important: false,
          isMeta: true,
          messageType: "SYSTEM",
        },
      });

      return NextResponse.json(
        {
          message: IDEALIZATION_END_MESSAGE_MODEL,
          suggestedPrompts: [],
        },
        { status: 200 },
      );
    }

    // ========================================================================
    // INICIALIZAR SERVI√áOS
    // ========================================================================
    const genAI = new GoogleGenerativeAI(env.GEMINI_API_KEY);

    // DEBUG: Verificar se safety settings est√£o corretas
    logger.info(
      {
        model: CHAT_CONFIG.ai.model,
        safetySettings: CHAT_CONFIG.ai.safetySettings,
      },
      "Criando modelo Gemini com safety settings",
    );

    const selectedModel = isInPauseMode
      ? CHAT_CONFIG.ai.pauseModel
      : CHAT_CONFIG.ai.model;

    logger.info(
      {
        model: selectedModel,
        mode: isInPauseMode ? "PAUSE (Economical)" : "NARRATIVE (Premium)",
      },
      "Selecionando modelo de IA",
    );

    const model = genAI.getGenerativeModel({
      model: selectedModel,
      safetySettings: CHAT_CONFIG.ai.safetySettings,
    });

    const historyOptimizer = new HistoryOptimizer(genAI, prismaClient);
    const suggestionGenerator = new SuggestionGenerator(genAI);
    const geminiClient = new GeminiClient(genAI);
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    // eslint-disable-next-line @typescript-eslint/ban-ts-comment
    // @ts-expect-error - prismaClient is an extended client
    const selectiveLoader = new SelectiveHistoryLoader(prismaClient);

    // ========================================================================
    // CONSTRUIR HIST√ìRICO (SELETIVO OU OTIMIZADO)
    // ========================================================================
    let history: GeminiMessage[];

    // Usar carregamento seletivo sempre (GENERAL foi convertido para PAUSAR_NARRATIVA)
    logger.info(
      { detectedCommand },
      "Usando carregamento seletivo de hist√≥rico",
    );
    const { messages, stats } = await selectiveLoader.loadSelectiveHistory(
      detectedCommand,
      conversationHistoryWithMessages.id,
    );

    // Converter mensagens para formato Gemini
    history = await historyOptimizer.buildOptimizedHistory(messages);

    logger.info({ stats }, "Hist√≥rico seletivo carregado e otimizado");

    // ========================================================================
    // INJETAR KNOWLEDGE BASE (SEMPRE)
    // ========================================================================
    const kbFormatter = new KnowledgeBaseFormatter();
    const kbMessages = await kbFormatter.loadKnowledgeBaseAsMessages(
      story.uuid,
      prompt, // ‚úÖ NOVO: UserMessage para busca sem√¢ntica
      3000, // ‚úÖ NOVO: Token budget para K adaptativo
    );

    if (kbMessages.length > 0) {
      // Converter KB para formato Gemini e injetar NO IN√çCIO
      const kbHistory =
        await historyOptimizer.buildOptimizedHistory(kbMessages);
      history = [...kbHistory, ...history];

      logger.info(
        { kbEntitiesCount: kbMessages.length / 2 },
        "Knowledge Base injetada no contexto",
      );
    }

    // Injetar prompt inicial do sistema (ap√≥s KB, antes do hist√≥rico)
    const initialSystemPrompt = buildInitialChatSystemPrompt(
      conversationHistoryWithMessages.customPrompt,
      isInPauseMode, // Passar modo pausa para incluir aviso se necess√°rio
    );

    let fullHistory = [...initialSystemPrompt, ...history];

    // Injetar override de modo pausa (ap√≥s hist√≥rico) quando aplic√°vel
    if (isInPauseMode && rawCommand === "GENERAL") {
      const pauseOverride = buildPauseModeOverrideMessage();
      fullHistory = [...fullHistory, ...pauseOverride];
      logger.info("Injetando mensagem de override de modo pausa no contexto");
    }

    const chat = model.startChat({
      history: fullHistory,
      generationConfig: {
        temperature: CHAT_CONFIG.ai.temperature,
      },
    });

    // ========================================================================
    // HELPER: GERA√á√ÉO DE RESUMO PARA MENSAGENS LONGAS
    // ========================================================================
    const generateSummaryIfNeeded = async (
      content: string,
    ): Promise<string | null> => {
      if (content.length <= 500) return null;

      try {
        const summarizer = new MessageSummarizer(genAI);
        const summary = await summarizer.summarizeMessage(content);
        logger.info(
          { contentLength: content.length, summaryLength: summary.length },
          "üìù Summary generated for long message",
        );
        return summary;
      } catch (error) {
        logger.error({ error }, "Failed to generate summary");
        return null;
      }
    };

    // ========================================================================
    // ENVIAR MENSAGEM E PROCESSAR STREAM
    // ========================================================================
    const { text: responseText, interrupted: wasInterrupted } =
      await geminiClient.sendMessageStream(chat, prompt, request.signal);

    // ========================================================================
    // DETEC√á√ÉO AUTOM√ÅTICA DE COMANDOS IMPORTANTES
    // ========================================================================
    const isImportantMessage = commandDetector.shouldMarkAsImportant(
      prompt,
      important,
    );

    if (commandDetector.hasApproveCommand(prompt)) {
      logger.info(
        "Comando [APROVAR E SELAR ESBO√áO] detectado - marcando como importante",
      );
    }

    if (commandDetector.hasReviewCommand(prompt)) {
      logger.info(
        "Comando [REVISAR E CORRIGIR SE√á√ÉO] detectado - marcando como importante",
      );
    }

    // Determinar se comando do usu√°rio deve ser meta (n√£o aparecer no hist√≥rico)
    const isUserCommandMeta = commandDetector.shouldMarkAsMeta(
      messageClassificationCommand, // ‚úÖ CORRIGIDO: usar comando real, n√£o historyLoadingCommand
    );

    if (isUserCommandMeta) {
      logger.info(
        { command: messageClassificationCommand },
        "Comando narrativo detectado - marcando mensagem do usu√°rio como meta",
      );
    }

    // ========================================================================
    // SALVAR MENSAGENS
    // ========================================================================
    // Calculate summary BEFORE transaction to avoid timeout (AI call can be slow)
    const userMessageSummary = await generateSummaryIfNeeded(prompt);

    // Salvar mensagem do usu√°rio DENTRO de transa√ß√£o
    const savedUserMessage = await prismaClient.$transaction(async (tx) => {
      const userMessage = await tx.message.create({
        data: {
          content: prompt,
          summary: userMessageSummary,
          role: "USER",
          conversationHistoryId: conversationHistoryWithMessages.id,
          important: isImportantMessage,
          isMeta: isUserCommandMeta,
          generateSuggestions: generateSuggestions,
          messageType: userMessageType,
          imageUrls: imageUrls || [],
        },
      });

      // Marcar imagens como usadas para prevenir limpeza
      if (imageUrls && imageUrls.length > 0) {
        await tx.uploadTracking.updateMany({
          where: {
            key: { in: imageUrls },
            used: false,
          },
          data: {
            used: true,
          },
        });
      }

      return userMessage;
    });

    // Se houve interrup√ß√£o, salvar mensagem de interrup√ß√£o
    if (wasInterrupted) {
      const interruptedMessage = await prismaClient.message.create({
        data: {
          content: CHAT_CONFIG.commands.interruptionMarker,
          role: "MODEL",
          conversationHistoryId: conversationHistoryWithMessages.id,
          important: false,
          isMeta: false,
          messageType: "SYSTEM",
        },
      });

      logger.warn(
        {
          messageId: interruptedMessage.id,
          conversationHistoryId: conversationHistoryWithMessages.id,
        },
        "Cliente abortou a requisi√ß√£o. Mensagem de interrup√ß√£o foi salva.",
      );

      return new NextResponse(null, { status: 499 }); // 499 Client Closed Request
    }

    // Salvar resposta do modelo
    const savedModelMessage = await prismaClient.message.create({
      data: {
        content: responseText,
        summary: await generateSummaryIfNeeded(responseText), // NOVO: Resumo persistente
        role: "MODEL",
        conversationHistoryId: conversationHistoryWithMessages.id,
        important: isImportantMessage,
        isMeta: isMeta,
        messageType: responseMessageType,
      },
    });

    // ========================================================================
    // DETEC√á√ÉO AUTOM√ÅTICA DE PAUSA PELA IA (VERIFICA√á√ÉO DE COER√äNCIA)
    // ========================================================================
    // Detectar se a IA pausou a narrativa devido a erro do autor
    // A IA informa a pausa em linguagem natural, n√£o com comando formatado
    const aiPauseIndicators = [
      /pausar?\s+a?\s*narrativa/i,
      /detectei\s+(?:um\s+)?erro/i,
      /identificou-se\s+(?:uma\s+)?viola[√ßc][√£a]o/i,
      /inconsist[√™e]ncia\s+detectada/i,
      /conflito\s+com/i,
      /n[√£a]o\s+(?:posso|poderei)\s+(?:prosseguir|continuar)/i,
    ];

    const aiInitiatedPause = aiPauseIndicators.some(
      (pattern) => pattern.test(responseText.substring(0, 500)), // Checar primeiros 500 chars
    );

    if (aiInitiatedPause && !isInPauseMode) {
      try {
        await prismaClient.conversationHistory.update({
          where: { id: conversationHistoryWithMessages.id },
          data: { pauseNarrativeMode: true },
        });

        logger.info(
          {
            conversationHistoryId: conversationHistoryWithMessages.id,
            trigger: "AI_INITIATED_PAUSE",
            messagePreview: responseText.substring(0, 200),
          },
          "ü§ñ IA pausou automaticamente a narrativa (Verifica√ß√£o de Coer√™ncia)",
        );
      } catch (error) {
        logger.error(
          { error },
          "Erro ao registrar pausa autom√°tica iniciada pela IA",
        );
      }
    }

    // ========================================================================
    // EXTRA√á√ÉO AUTOM√ÅTICA DE CONHECIMENTO
    // ========================================================================
    // Extrair de:
    // 1. SECTION_CONTENT (conte√∫do gerado pela IA)
    // 2. SECTION_PROPOSAL (propostas podem ter informa√ß√µes)
    // 3. PAUSAR_NARRATIVA (conversas podem introduzir informa√ß√µes)
    // 4. Mensagens do USU√ÅRIO com comandos APROVAR ou SUGERIR (usu√°rio passa contexto)
    const shouldExtractFromResponse =
      responseMessageType === "SECTION_CONTENT" ||
      responseMessageType === "SECTION_PROPOSAL" ||
      (responseMessageType === "GENERAL" && isInPauseMode);

    const shouldExtractFromUserInput =
      userMessageType === "SECTION_PROPOSAL" || // SUGERIR_PROXIMA_SECAO
      userMessageType === "SECTION_CONTENT"; // APROVAR_E_SELAR_ESBO√áO

    if (shouldExtractFromResponse || shouldExtractFromUserInput) {
      try {
        // Determinar de onde extrair
        const contentToExtract = shouldExtractFromUserInput
          ? prompt // Extrair do prompt do usu√°rio
          : responseText; // Extrair da resposta da IA

        const sourceType = shouldExtractFromUserInput
          ? "user input"
          : "AI response";

        logger.info(
          {
            storyId: story.uuid,
            trigger: shouldExtractFromUserInput
              ? `User Input (${userMessageType})`
              : `AI Response (${responseMessageType})`,
            contentPreview: `${contentToExtract.substring(0, 100)}...`,
          },
          "üöÄ GATILHO DETECTADO: Iniciando extra√ß√£o de conhecimento...",
        );

        // Carregar entidades existentes para contexto
        const existingEntities = await prismaClient.storyEntity.findMany({
          where: {
            storyId: story.uuid,
            status: "ACTIVE", // ‚úÖ Apenas entidades ativas
          },
          select: { name: true, type: true },
        });

        // Extrair entidades e relacionamentos do conte√∫do
        const extractor = new KnowledgeExtractor();
        const extractionResult: ExtractionResult =
          await extractor.extractFromContent(
            contentToExtract,
            existingEntities,
            story.uuid,
          );

        // Processar e salvar entidades
        if (extractionResult.entities.length > 0) {
          const manager = new EntityManager();
          const result = await manager.processExtractedEntities(
            story.uuid,
            extractionResult.entities,
            shouldExtractFromUserInput
              ? savedUserMessage.id
              : savedModelMessage.id,
          );

          logger.info(
            {
              storyId: story.uuid,
              source: sourceType,
              ...result,
            },
            `‚úÖ Entidades processadas! Created: ${result.created}, Updated: ${result.updated}, Skipped: ${result.skipped}`,
          );
        }

        // Processar e salvar relacionamentos
        if (extractionResult.relationships.length > 0) {
          const relationshipManager = new RelationshipManager();
          const relationshipsCreated =
            await relationshipManager.processExtractedRelationships(
              story.uuid,
              extractionResult.relationships,
              shouldExtractFromUserInput
                ? savedUserMessage.id
                : savedModelMessage.id,
            );

          logger.info(
            {
              storyId: story.uuid,
              source: sourceType,
              relationshipsCreated,
            },
            `üîó Relacionamentos processados! Created: ${relationshipsCreated}`,
          );
        } else {
          logger.info(
            { storyId: story.uuid, source: sourceType },
            "ü§∑‚Äç‚ôÇÔ∏è Extra√ß√£o finalizada, mas nenhuma entidade relevante foi retornada pela IA.",
          );
        }
      } catch (error) {
        // Falha silenciosa - n√£o bloqueia o fluxo principal
        logger.error(
          { error, storyId: story.uuid },
          "Erro ao extrair conhecimento (n√£o cr√≠tico)",
        );
      }
    }

    // ========================================================================
    // GERAR SUGEST√ïES (SE SOLICITADO)
    // ========================================================================
    let suggestedPrompts: string[] = [];

    if (generateSuggestions) {
      suggestedPrompts = await suggestionGenerator.generateSuggestedPrompts(
        history,
        responseText,
      );
    }

    return NextResponse.json(
      {
        message: responseText,
        messageId: savedModelMessage.id,
        suggestedPrompts,
      },
      { status: 200 },
    );
  } catch (err) {
    return await apiErrorHandler(err);
  }
}

export async function GET(
  _request: NextRequest,
  { params }: { params: Promise<{ uuid: string }> },
) {
  try {
    const user = await getAuthenticatedUser();
    const { uuid } = await params;

    const story = await prismaClient.story.findUnique({
      where: { uuid: uuid },
      include: {
        conversationHistory: {
          include: {
            messages: {
              orderBy: { id: "asc" },
            },
          },
        },
      },
    });

    if (!story) {
      throw new HttpExceptionClient(404, "Hist√≥ria n√£o encontrada");
    }

    if (story.userId !== user.id) {
      throw new HttpExceptionClient(404, "Hist√≥ria n√£o encontrada");
    }

    const historyData = story.conversationHistory;
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const chatSessionReference = Array.isArray(historyData)
      ? historyData[0]
      : historyData;

    const messagesFromDb = chatSessionReference?.messages || [];

    // Map messages to include dbId for frontend use
    const messages = messagesFromDb.map(
      (msg: { id: { toString: () => string } }) => ({
        ...msg,
        id: msg.id.toString(), // Convert to string for React keys
        dbId: msg.id, // Keep numeric ID for API calls
      }),
    );

    return NextResponse.json(
      {
        messages,
      },
      { status: 200 },
    );
  } catch (err) {
    return await apiErrorHandler(err);
  }
}
